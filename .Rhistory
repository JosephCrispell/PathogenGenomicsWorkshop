# Calculate the correlation and r squared values
correlation <- cor(actual, predicted)
rSq <- correlation^2
# Add a legend detailing the correlation and r squared values
legend("topleft", c(paste("corr =", round(correlation, digits=2)),
paste("Rsq = ", round(rSq, digits=2))),
bty="n", cex = 1)
}
findOptimalMtry <- function(response, predictors, mTryInitial, nTrees, plot){
tuneOutput <- tuneRF(predictors, response, mtryStart=mTryInitial,
ntreeTry=nTrees, stepFactor=1.5, improve=0.0001, trace=FALSE,
plot=FALSE)
optimalMtry <- as.integer(rownames(tuneOutput)[tuneOutput[,2] == min(tuneOutput[,2])])
if(plot == TRUE){
plot(tuneOutput, las=1)
abline(v=optimalMtry, col="red", lty=2)
}
return(optimalMtry)
}
plotEpidemiologicalMetricDistributionsWithMissingData <- function(table, fullNames,
selection){
# Get the column names of the genetic vs. epi metrics table
colNames <- colnames(table)
# Initialise an array to store the proportion of missing data for each metric
propMissing <- calculateProportionMissingData(table)
# Examine each epidemiological metric
for(col in 1:ncol(table)){
# Check if negative values are present in dataset
if(length(which(as.numeric(table[, col]) < 0)) > 0){
cat(paste("Found ", length(which(table[, col] < 0)), " missing entries for: ",
colNames[col], "\n", sep=""))
# Check if column is a factor
if(is.factor(table[, col]) == TRUE){
plot(table[, col], las=1, main=colNames[col])
}else{
hist(table[, col], las=1, main=colNames[col], xlab="value", breaks=200,
border="black", col="black")
}
}
}
# Get the order by proportion missing data
order <- order(propMissing)
# Get the full names of the metrics
variableNames <- getFullVariableNames(colnames(table), fullNames)
# Get the margin sizes - to fit in metric names
marginSizes <- list(
"BB" = 26,
"CC" = 33,
"CB" = 22,
"BC" = 22
)
par(mar=c(0,marginSizes[[selection]],2,0.5)) # bottom, left, top, right
plot <- barplot(propMissing[order], horiz=TRUE,
beside=TRUE,
main="Proportion Missing Data")
at <- plot[,1]
xLabPosition <- 0
text(labels=variableNames[order],
x=rep(xLabPosition,length(propMissing)),
y=at, srt = 0, pos = 2, xpd = TRUE, cex=0.75)
spacing <- at[2] - at[1]
ticks <- seq(0,1,0.1)
ticks <- ticks[ticks < max(propMissing)]
axis(side=3, at=ticks, line=-spacing*1.2, mgp=c(3, .5, 0))
# Reset margins
par(mar=c(5.1,4.1,4.1,2.1))
}
makeBooleanColumnsFactors <- function(table){
colNames <- colnames(table)
for(col in 1:ncol(table)){
if((grepl(x=colNames[col], pattern="Same") == TRUE &
grepl(x=colNames[col], pattern="PeriodSpentIn") == FALSE) ||
grepl(x=colNames[col], pattern="Boolean") == TRUE){
table[, col] <- as.factor(table[, col])
}
}
return(table)
}
removeColumnsIfNotRelevant <- function(table){
# For particular comparisons: Badger-Badger, Badger-Cattle, Cattle-Cattle
# some epidemiological metrics aren't relevant and column will be filled
# with -1
colsToRemove <- c()
columnsToConsider <- which(colnames(table) %in% c("GeneticDistance", "iSpeciesJSpecies",
"IsolateI", "IsolateJ") == FALSE)
for(col in columnsToConsider){
if(sd(table[, col]) == 0){
colsToRemove[length(colsToRemove) + 1] <- col
cat(paste("Removed: ", colnames(table)[col], "\n", sep=""))
}
}
return(table[, -colsToRemove])
}
source('~/Desktop/Research/GeneralTools/WoodchesterPark/RandomForestAndBoostedRegression/FitRandomForestAndBoostedRegressionToEpiMetrics_BB-CC-CB_10-08-17.R')
source('~/Desktop/Research/GeneralTools/WoodchesterPark/RandomForestAndBoostedRegression/FitRandomForestAndBoostedRegressionToEpiMetrics_BB-CC-CB_10-08-17.R')
source('~/Desktop/Research/GeneralTools/WoodchesterPark/RandomForestAndBoostedRegression/FitRandomForestAndBoostedRegressionToEpiMetrics_BB-CC-CB_10-08-17.R')
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17))
data
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17))
people <- list()
for(row in 1:nrow(data)){
people[[data[row, "Name"]]] <- data[row, "Age"]
}
people
data[row, "Name"]
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17), stringsAsFactors=FALSE)
people <- list()
for(row in 1:nrow(data)){
people[[data[row, "Name"]]] <- data[row, "Age"]
}
people
?assign
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17), stringsAsFactors=FALSE)
#people <- list()
for(row in 1:nrow(data)){
#people[[data[row, "Name"]]] <- data[row, "Age"]
assign(x=data[row, "Name"], value=data[row, "Age"])
}
Evie
a <- c(0,"D",0,"E",0,"F")
b <- c(0,"E",0,"F",0,"D")
c <- data.frame(a, b, stringsAsFactors=FALSE)
c
seq(from=1, to=nrow(c), by=2)
row <- 1
c[row, ]
c[row+1, ]
paste0(c[row, ], c[row+1, ])
for(row in seq(from=1, to=nrow(c), by=2)){
c[row, ] <- paste0(c[row+1, ], c[row, ])
}
c
print(c)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
data <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
dividebyLag <- function(data, column){
treegrowth[, column] <- treegrowth[, column] / lag(treegrowth[, column])
}
data <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(data)[-1]){
data[, column] <- divideByLag(data, column)
}
divideByLag <- function(data, column){
treegrowth[, column] <- treegrowth[, column] / lag(treegrowth[, column])
}
data <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(data)[-1]){
data[, column] <- divideByLag(data, column)
}
divideByLag <- function(data, column){
data[, column] <- data[, column] / lag(data[, column])
}
treeGrowth <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(treeGrowth)[-1]){
treeGrowth[, column] <- divideByLag(treeGrowth, column)
}
treeGrowth
colnames(treeGrowth)[-1]
treeGrowth <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(treeGrowth)[-1]){
treeGrowth[, paste0(column, "_growth")] <- divideByLag(treeGrowth, column)
}
treeGrowth
lag(treeGrowth$tree1)
treeGrowth$tree1
treeGrowth$tree1 / lag(treeGrowth$tree1)
treeGrowth <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(treeGrowth)[-1]){
treeGrowth[, paste0(column, "_growth")] <- c(1, treeGrowth[-1, column] / treeGrowth[-nrow(data), column])
}
treeGrowth
getwd()
# Read in the data file
file <- "/home/josephcrispell/Downloads/datasheet.csv"
data <- read.table(file, header=TRUE, sep=",", stringsAsFactors=FALSE)
head(data)
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd)
nrow(data)
# Read in the data file
file <- "/home/josephcrispell/Downloads/datasheet.csv"
data <- read.table(file, header=TRUE, sep=",", stringsAsFactors=FALSE)
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd)
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l")
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1)
?polygon
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)))
?polygon
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1)
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0)col=rgb(0,0,0, 0.5))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.5))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.5))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.5))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.1))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.1))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,0, 0.1))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,0, 1))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,1, 0.75))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,1, 0.75))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)), lwd=2, lty=3)
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Set the path variable
path <- "/home/josephcrispell/Desktop/Research/RepublicOfIreland/Mbovis/Monaghan/Fastqs_24-09-19/FASTQC/"
# Read in the FASTQC file summary table
summaryFile <- paste0(path, "Fastqc_summary_24-09-19.txt")
summary <- read.table(summaryFile, header=TRUE, sep="\t", stringsAsFactors=FALSE)
# Look at GC distribution
hist(summary$GC, breaks=20, las=1)
boxplot(summary$LeftTrim, summary$RightTrim, names=c("LEFT", "RIGHT"), las=1, frame=FALSE,
main="Trimming suggestions", outcol=rgb(0,0,0, 0.1), pch=19)
# Check adapter flag
table(summary$AdapterContentFlag)
head(summary])
head(summary)
# Look at the number of reads distribution
hist(summary$NumberReads, breaks=100, las=1)
summary(summary$NumberReads)
summary$FileName[which(summary$NumberReads < 250000)]
summary[which(summary$NumberReads < 250000), c("FileName", "NumberReads")]
# Sort the file names
summary <- summary[order(summary$FileName), ]
# Look at GC distribution
hist(summary$GC, breaks=20, las=1)
boxplot(summary$LeftTrim, summary$RightTrim, names=c("LEFT", "RIGHT"), las=1, frame=FALSE,
main="Trimming suggestions", outcol=rgb(0,0,0, 0.1), pch=19)
# Check adapter flag
table(summary$AdapterContentFlag)
# Look at the number of reads distribution
hist(summary$NumberReads, breaks=100, las=1)
summary[which(summary$NumberReads < 250000), c("FileName", "NumberReads")]
summary[which(summary$NumberReads > 1000000), c("FileName", "NumberReads")]
summary[which(summary$GC != 65), c("FileName", "NumberReads")]
summary[which(summary$GC != 65), c("FileName", "GC")]
# Look at the read length distribution
table(summary$ReadLength)
path <- "/home/josephcrispell/Desktop/Research/RepublicOfIreland/Mbovis/Monaghan/vcfFiles/"
##########################
# Read in coverage files #
##########################
# # Read in the genome coverage file
# genomeCoverageFile <- paste(path, "genomeCoverageSummary_DP-20_21-07-2017.txt", sep="")
# genomeCoverage <- read.table(genomeCoverageFile, header=TRUE, stringsAsFactors=FALSE)
# Read in the isolate coverage file
isolateCoverageFile <- paste(path, "isolateCoverageSummary_DP-20_30-07-2019.txt", sep="")
isolateCoverage <- read.table(isolateCoverageFile, header=TRUE, stringsAsFactors=FALSE)
# Read in the isolate coverage file
isolateCoverageFile <- paste(path, "isolateCoverageSummary_DP-20_24-09-2019.txt", sep="")
isolateCoverage <- read.table(isolateCoverageFile, header=TRUE, stringsAsFactors=FALSE)
# Parse the Isolate column
isolateCoverage$IsolateID <- parseIsolateColumn(isolateCoverage$IsolateID)
parseIsolateColumn <- function(column){
ids <- c()
for(i in 1:length(column)){
parts <- strsplit(column[i], split="_")[[1]]
ids[i] <- paste(parts[1], "_", parts[2], sep="")
}
return(ids)
}
# Parse the Isolate column
isolateCoverage$IsolateID <- parseIsolateColumn(isolateCoverage$IsolateID)
plot(y=isolateCoverage$PercentageCoverage,
x=isolateCoverage$MeanDepth,
las=1, ylab="Proportion", main="Proportion of M. bovis Genome with >19 mapped reads",
xlab="Mean Read Depth", pch=16, cex=3,
col=ifelse(grepl(x=isolateCoverage$IsolateID, pattern="WB"), rgb(1,0,0, 0.5),
rgb(0,0,1, 0.5)))
head(isolateCoverage)
isolateCoverage[isolateCoverage$PercentageCoverage < 0.1, ]
packageVersion("devtools")
library(devtools)
devtools::create()
library("devtools")
library("roxygen2")
packageDirectory <- "/home/josephcrispell/Desktop/pathogenGenomicsWorkshop/"
create(packageDirectory)
setwd(packageDirectory)
document()
document()
devtools::install_github("JosephCrispell/pathogenGenomicsWorkshop")
knitr::opts_chunk$set(echo = TRUE)
# Set your working directory
setwd(file.path("~", "Desktop", ""))
# Installing the 'ape' package
install.packages("ape", repos="https://cloud.r-project.org")
# Installing the 'phangorn' package
install.packages("phangorn", repos="https://cloud.r-project.org")
# Installing the 'PathogenGenomicsWorkshopPackage' package
#install.packages("devtools", repos="https://cloud.r-project.org")
#devtools::install_github("JosephCrispell/PathogenGenomicsWorkshopPackage")
# Load the required libraries
suppressWarnings(library(ape)) # For reading in sequence
suppressWarnings(library(phangorn)) # For testing substitution models and building and plotting the phylogeny
#library(PathogenGenomicsWorkshopPackage) # Our custom package for the current course
source("PathogenGenomicsWorkshop_FUNCTIONS_12-09-19.R") # REMOVE ONCE CUSTOM R PACKAGE MADE!
# Load the required libraries
suppressWarnings(library(ape)) # For reading in sequence
suppressWarnings(library(phangorn)) # For testing substitution models and building and plotting the phylogeny
suppressWarnings(library(pathogenGenomicsWorkshop)) # Our custom package for the current course
# Load the required libraries
suppressWarnings(library(ape)) # For reading in sequence
suppressWarnings(library(phangorn)) # For testing substitution models and building and plotting the phylogeny
suppressWarnings(library(pathogenGenomicsWorkshop)) # Our custom package for the current course
# Load the required libraries
library(ape) # For reading in sequence
library(phangorn) # For testing substitution models and building and plotting the phylogeny
#library(PathogenGenomicsWorkshopPackage) # Our custom package for the current course
source("PathogenGenomicsWorkshop_FUNCTIONS_12-09-19.R") # REMOVE ONCE CUSTOM R PACKAGE MADE!
# Load the required libraries
library(ape) # For reading in sequence
library(phangorn) # For testing substitution models and building and plotting the phylogeny
library(pathogenGenomicsWorkshop) # Our custom package for the current course
# Get the current date
today <- format(Sys.Date(), "%d-%m-%y")
# Read in the FASTA file
fastaFile <- system.file("extdata", "Wicklow_Mbovis.fasta", package = "pathogenGenomicsWorkshop")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
nucleotideAlignment <- toupper(nucleotideAlignment) # Convert the nucleotides to upper case
# Read in the genome positions
positionsFile <- system.file("extdata", "fastaPositions.txt", package = "pathogenGenomicsWorkshop")
genomePositions <- read.table(positionsFile, header=TRUE)
# Plot the positions of the FASTA positions
hist(genomePositions$Position, breaks=1000, las=1,
main="Positions of sites in the FASTA nucleotide alignment",
xlab="Position")
plotFASTA(nucleotideAlignment, pdfFileName=paste0("FullNucleotideAlignment_", today, ".pdf"))
plotFASTA(nucleotideAlignment)
# Count the nucleotides at each site in the alignment
nucleotideCountsAtEachSite <- countNucleotidesAtEachSite(nucleotideAlignment)
# Identify the uninformative sites
uninformativeSites <- which(nucleotideCountsAtEachSite < 2)
# Create a new nucleotide alignment without the uninformative sites
nucleotideAlignmentInformative <- nucleotideAlignment[, -uninformativeSites]
informativeGenomePositions <- genomePositions[-uninformativeSites, ]
plotFASTA(nucleotideAlignmentInformative, pdfFileName=paste0("InformativeSitesAlignment_", today, ".pdf"))
plotFASTA(nucleotideAlignmentInformative)
# Extract metadata from sequences
sequenceInfo <- getSequenceInfoFromNames(rownames(nucleotideAlignment))
# Take a quick look at the metadata
head(sequenceInfo)
# Calculate the proportion of Ns for each sequence
proportionNsInInformativeSites <- calculateProportionNsOfEachSequence(nucleotideAlignmentInformative)
# Plot these values
hist(proportionNsInInformativeSites, breaks=50, las=1, xlab="Proportion of Ns",
main="Quality of nucleotide sequences (informative sites only)")
# Build a genetic distance matrix
distances <- dist.dna(as.DNAbin(nucleotideAlignmentInformative), model="raw")
# Build a quick initial phylogenetic tree
initialNJTree <- nj(distances)
# Load the maximum likelihood tree data object - don't want to run algorithm everytime! INCLUDE IN PACKAGE
# distances
# initialNJTree
# fittingOutput
# Maybe also include all the over data??
# Convert the nucleotide sequences into the PHYDAT format
sequencesInPhyDatFormat <- phyDat(nucleotideAlignmentInformative, type="DNA")
# Compute likelihood of the initial Neighbour Joining tree given sequences
likelihoodObject <- pml(initialNJTree, sequencesInPhyDatFormat)
# Run maximum likelihood
fittingOutput <- optim.pml(likelihoodObject,
optNni = TRUE, # Optimise topology
optInv = TRUE, # Optimise proportion of variable sites
optBf = TRUE, # Optimise the base frequencies
model = "HKY", # Substitution model
rearrangement = "NNI", # Nearest Neighbour Interchanges
control = pml.control(maxit=100000)) # Set the maximum number of iterations
mlTreeBS$edge.length
remove.packages("pathogenGenomicsWorkshop")
devtools::install_github("JosephCrispell/pathogenGenomicsWorkshop")
# Set your working directory
setwd(file.path("~", "Desktop", ""))
# Installing the 'ape' package
install.packages("ape", repos="https://cloud.r-project.org")
# Installing the 'phangorn' package
install.packages("phangorn", repos="https://cloud.r-project.org")
# Installing the 'pathogenGenomicsPackage' package
install.packages("devtools", repos="https://cloud.r-project.org")
devtools::install_github("JosephCrispell/pathogenGenomicsWorkshop")
# Load the required libraries
suppressWarnings(library(ape)) # For reading in sequence
suppressWarnings(library(phangorn)) # For testing substitution models and building and plotting the phylogeny
suppressWarnings(library(pathogenGenomicsWorkshop)) # Our custom package for the current course
# Get the current date
today <- format(Sys.Date(), "%d-%m-%y")
# Read in the FASTA file
fastaFile <- system.file("extdata", "Wicklow_Mbovis.fasta", package = "pathogenGenomicsWorkshop")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
nucleotideAlignment <- toupper(nucleotideAlignment) # Convert the nucleotides to upper case
# Read in the genome positions
positionsFile <- system.file("extdata", "fastaPositions.txt", package = "pathogenGenomicsWorkshop")
genomePositions <- read.table(positionsFile, header=TRUE)
# Plot the positions of the FASTA positions
hist(genomePositions$Position, breaks=1000, las=1,
main="Positions of sites in the FASTA nucleotide alignment",
xlab="Position")
plotFASTA(nucleotideAlignment, pdfFileName=paste0("FullNucleotideAlignment_", today, ".pdf"))
plotFASTA(nucleotideAlignment, pdfFileName=paste0("FullNucleotideAlignment_", today, ".pdf"))
# Count the nucleotides at each site in the alignment
nucleotideCountsAtEachSite <- countNucleotidesAtEachSite(nucleotideAlignment)
# Identify the uninformative sites
uninformativeSites <- which(nucleotideCountsAtEachSite < 2)
# Create a new nucleotide alignment without the uninformative sites
nucleotideAlignmentInformative <- nucleotideAlignment[, -uninformativeSites]
informativeGenomePositions <- genomePositions[-uninformativeSites, ]
# Extract metadata from sequences
sequenceInfo <- getSequenceInfoFromNames(rownames(nucleotideAlignment))
# Take a quick look at the metadata
head(sequenceInfo)
# Calculate the proportion of Ns for each sequence
proportionNsInInformativeSites <- calculateProportionNsOfEachSequence(nucleotideAlignmentInformative)
# Plot these values
hist(proportionNsInInformativeSites, breaks=50, las=1, xlab="Proportion of Ns",
main="Quality of nucleotide sequences (informative sites only)")
# Build a genetic distance matrix
distances <- dist.dna(as.DNAbin(nucleotideAlignmentInformative), model="raw")
# Build a quick initial phylogenetic tree
initialNJTree <- nj(distances)
# Convert the nucleotide sequences into the PHYDAT format
sequencesInPhyDatFormat <- phyDat(nucleotideAlignmentInformative, type="DNA")
# Compute likelihood of the initial Neighbour Joining tree given sequences
likelihoodObject <- pml(initialNJTree, sequencesInPhyDatFormat)
# Run maximum likelihood
fittingOutput <- optim.pml(likelihoodObject,
optNni = TRUE, # Optimise topology
optInv = TRUE, # Optimise proportion of variable sites
optBf = TRUE, # Optimise the base frequencies
model = "HKY", # Substitution model
rearrangement = "NNI", # Nearest Neighbour Interchanges
control = pml.control(maxit=100000)) # Set the maximum number of iterations
# Build a bootstrapped maximum likelihood phylogeny
bootstrapResults <- bootstrap.pml(fittingOutput,
bs = 100,
jumble = TRUE,
control = pml.control(maxit=100000)) # Set the maximum number of iterations
# Get phylogenetic tree with bootstrap values
# Returns phylogenetic tree with bootstrap values as node labels
mlTreeBS <- plotBS(fittingOutput$tree, bootstrapResults, type="fan") # Type of phylogenetic tree shape to plot
remove(bootstrapResults, data, fittingOutput, genomePositions, initialNJTree, likelihoodObject, nucleotideAlignment, nucleotideAlignmentInformative, sequenceInfo, sequencesInPhyDatFormat, distances, fastaFile, file, informativeGenomePositions, nucleotideCountsAtEachSite, packageDirectory, positionsFile, proportionNsInInformativeSites, today, uninformativeSites, addLinearComparisonInset, assignMetricColours, calculateCorrelationBetweenEpiMetrics, calculateProportionMissingData, checkForMatch, doubleUpRowNames, findOptimalMtry, getClusterSizes, getFullVariableNames, getVariableColours, indexArray, makeBooleanColumnsFactors, noteClustersOfMetrics, noteFullNames, noteVariableImportance, noteVariableImportanceOLD, plotBRPredictorVariableTrends, plotClusterColours, plotEpidemiologicalMetricDistributionsWithMissingData, plotHeatmap, plotPredictedVersusActual, plotRawPredictorVersusResponse, plotRFPredictorVariableTrendsDOESNTWORK, plotVariableImportance, plotVariableImportanceAgainstNMetricsRemoved, plotVariableImportanceAgainstNMetricsRemovedPerCluster, removeColumnsIfNotRelevant, removeLeastInformativeMetric, removeMetricWithMostMissingData, removeVariablesByImportanceFromClustersAndTable, runRandomForestAnalysesIncrementallyRemovingMetricsBasedOnInformativeness, runRandomForestAnalysesIncrementallyRemovingMetricsBasedOnInformativeness, runRandomForestAnalysesIncrementallyRemovingMetricsFromCorrelationClusters, runRandomForestAnalysesIncrementallyRemovingMetricsWithMissingData, selectAppropriateComparisonsForSelection, selectGeneticDistancesBelowThreshold)
remove(plotVariableImportanceAsScatterPlot, returnVariableColour)
mlTreeBS$edge.length
save.image("~/Desktop/pathogenGenomicsWorkshop/data/mlTreeBS.RData")
remove.packages("pathogenGenomicsWorkshop")
library("devtools")
library("roxygen2")
packageDirectory <- "/home/josephcrispell/Desktop/pathogenGenomicsWorkshop/"
setwd(packageDirectory)
#document()
document()
document()
document()
document()
