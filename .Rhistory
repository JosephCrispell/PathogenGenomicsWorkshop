#     4     3
#     2     1
# 1. Heatmap
# 2. Row Dendrogram
# 3. Column Dendrogram
# 4. Key
lmat=rbind(4:3, 2:1),
# Set the size of the spaces for output plots:
#     Colour Key      |   Column Dendrogram
#     -------------------------------------
#     Row Dendrogram  |   Heatmap
#
# Note that these will be affected by the width and height you set for the PDF
lhei=c(0.1, 10), # c(row1Width, row2Width)
lwid=c(0.1, 10), # c(column1Width, column2Width)
# Note that the input matrix is not symmetric
symm = FALSE
)
}
plotPredictedVersusActual <- function(actual, predicted, main="Predicted vs. Actual genetic distances"){
# Plot the predicted versus actual
plot(x=predicted, y=actual,
las=1, pch=19, col=rgb(0,0,0, 0.1), xlab="Predicted", ylab="Actual", main=main)
abline(lm(actual ~ predicted), col="red")
# Calculate the correlation and r squared values
correlation <- cor(actual, predicted)
rSq <- correlation^2
# Add a legend detailing the correlation and r squared values
legend("topleft", c(paste("corr =", round(correlation, digits=2)),
paste("Rsq = ", round(rSq, digits=2))),
bty="n", cex = 1)
}
findOptimalMtry <- function(response, predictors, mTryInitial, nTrees, plot){
tuneOutput <- tuneRF(predictors, response, mtryStart=mTryInitial,
ntreeTry=nTrees, stepFactor=1.5, improve=0.0001, trace=FALSE,
plot=FALSE)
optimalMtry <- as.integer(rownames(tuneOutput)[tuneOutput[,2] == min(tuneOutput[,2])])
if(plot == TRUE){
plot(tuneOutput, las=1)
abline(v=optimalMtry, col="red", lty=2)
}
return(optimalMtry)
}
plotEpidemiologicalMetricDistributionsWithMissingData <- function(table, fullNames,
selection){
# Get the column names of the genetic vs. epi metrics table
colNames <- colnames(table)
# Initialise an array to store the proportion of missing data for each metric
propMissing <- calculateProportionMissingData(table)
# Examine each epidemiological metric
for(col in 1:ncol(table)){
# Check if negative values are present in dataset
if(length(which(as.numeric(table[, col]) < 0)) > 0){
cat(paste("Found ", length(which(table[, col] < 0)), " missing entries for: ",
colNames[col], "\n", sep=""))
# Check if column is a factor
if(is.factor(table[, col]) == TRUE){
plot(table[, col], las=1, main=colNames[col])
}else{
hist(table[, col], las=1, main=colNames[col], xlab="value", breaks=200,
border="black", col="black")
}
}
}
# Get the order by proportion missing data
order <- order(propMissing)
# Get the full names of the metrics
variableNames <- getFullVariableNames(colnames(table), fullNames)
# Get the margin sizes - to fit in metric names
marginSizes <- list(
"BB" = 26,
"CC" = 33,
"CB" = 22,
"BC" = 22
)
par(mar=c(0,marginSizes[[selection]],2,0.5)) # bottom, left, top, right
plot <- barplot(propMissing[order], horiz=TRUE,
beside=TRUE,
main="Proportion Missing Data")
at <- plot[,1]
xLabPosition <- 0
text(labels=variableNames[order],
x=rep(xLabPosition,length(propMissing)),
y=at, srt = 0, pos = 2, xpd = TRUE, cex=0.75)
spacing <- at[2] - at[1]
ticks <- seq(0,1,0.1)
ticks <- ticks[ticks < max(propMissing)]
axis(side=3, at=ticks, line=-spacing*1.2, mgp=c(3, .5, 0))
# Reset margins
par(mar=c(5.1,4.1,4.1,2.1))
}
makeBooleanColumnsFactors <- function(table){
colNames <- colnames(table)
for(col in 1:ncol(table)){
if((grepl(x=colNames[col], pattern="Same") == TRUE &
grepl(x=colNames[col], pattern="PeriodSpentIn") == FALSE) ||
grepl(x=colNames[col], pattern="Boolean") == TRUE){
table[, col] <- as.factor(table[, col])
}
}
return(table)
}
removeColumnsIfNotRelevant <- function(table){
# For particular comparisons: Badger-Badger, Badger-Cattle, Cattle-Cattle
# some epidemiological metrics aren't relevant and column will be filled
# with -1
colsToRemove <- c()
columnsToConsider <- which(colnames(table) %in% c("GeneticDistance", "iSpeciesJSpecies",
"IsolateI", "IsolateJ") == FALSE)
for(col in columnsToConsider){
if(sd(table[, col]) == 0){
colsToRemove[length(colsToRemove) + 1] <- col
cat(paste("Removed: ", colnames(table)[col], "\n", sep=""))
}
}
return(table[, -colsToRemove])
}
source('~/Desktop/Research/GeneralTools/WoodchesterPark/RandomForestAndBoostedRegression/FitRandomForestAndBoostedRegressionToEpiMetrics_BB-CC-CB_10-08-17.R')
source('~/Desktop/Research/GeneralTools/WoodchesterPark/RandomForestAndBoostedRegression/FitRandomForestAndBoostedRegressionToEpiMetrics_BB-CC-CB_10-08-17.R')
source('~/Desktop/Research/GeneralTools/WoodchesterPark/RandomForestAndBoostedRegression/FitRandomForestAndBoostedRegressionToEpiMetrics_BB-CC-CB_10-08-17.R')
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17))
data
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17))
people <- list()
for(row in 1:nrow(data)){
people[[data[row, "Name"]]] <- data[row, "Age"]
}
people
data[row, "Name"]
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17), stringsAsFactors=FALSE)
people <- list()
for(row in 1:nrow(data)){
people[[data[row, "Name"]]] <- data[row, "Age"]
}
people
?assign
data <- data.frame("Name"=c("John", "Evie", "Graham", "Mary"), "Age"=c(13,43,26,17), stringsAsFactors=FALSE)
#people <- list()
for(row in 1:nrow(data)){
#people[[data[row, "Name"]]] <- data[row, "Age"]
assign(x=data[row, "Name"], value=data[row, "Age"])
}
Evie
a <- c(0,"D",0,"E",0,"F")
b <- c(0,"E",0,"F",0,"D")
c <- data.frame(a, b, stringsAsFactors=FALSE)
c
seq(from=1, to=nrow(c), by=2)
row <- 1
c[row, ]
c[row+1, ]
paste0(c[row, ], c[row+1, ])
for(row in seq(from=1, to=nrow(c), by=2)){
c[row, ] <- paste0(c[row+1, ], c[row, ])
}
c
print(c)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
Films <- 1:100
Gekeken <- c(2,6,30,45,86,14,22,40,13,15,16)
sample(Films[-Gekeken],1)
data <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
dividebyLag <- function(data, column){
treegrowth[, column] <- treegrowth[, column] / lag(treegrowth[, column])
}
data <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(data)[-1]){
data[, column] <- divideByLag(data, column)
}
divideByLag <- function(data, column){
treegrowth[, column] <- treegrowth[, column] / lag(treegrowth[, column])
}
data <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(data)[-1]){
data[, column] <- divideByLag(data, column)
}
divideByLag <- function(data, column){
data[, column] <- data[, column] / lag(data[, column])
}
treeGrowth <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(treeGrowth)[-1]){
treeGrowth[, column] <- divideByLag(treeGrowth, column)
}
treeGrowth
colnames(treeGrowth)[-1]
treeGrowth <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(treeGrowth)[-1]){
treeGrowth[, paste0(column, "_growth")] <- divideByLag(treeGrowth, column)
}
treeGrowth
lag(treeGrowth$tree1)
treeGrowth$tree1
treeGrowth$tree1 / lag(treeGrowth$tree1)
treeGrowth <- data.frame("year"=c(1900, 1901, 1902), "tree1"=c(0.72, 0.56, 1.23), "tree2"=c(0.34, 0.88, 0.56), "tree3"=c(1.34, 0.98, 1.67))
for(column in colnames(treeGrowth)[-1]){
treeGrowth[, paste0(column, "_growth")] <- c(1, treeGrowth[-1, column] / treeGrowth[-nrow(data), column])
}
treeGrowth
getwd()
# Read in the data file
file <- "/home/josephcrispell/Downloads/datasheet.csv"
data <- read.table(file, header=TRUE, sep=",", stringsAsFactors=FALSE)
head(data)
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd)
nrow(data)
# Read in the data file
file <- "/home/josephcrispell/Downloads/datasheet.csv"
data <- read.table(file, header=TRUE, sep=",", stringsAsFactors=FALSE)
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd)
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l")
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1)
?polygon
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)))
?polygon
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1)
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0)col=rgb(0,0,0, 0.5))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.5))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.5))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.5))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.1))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.1))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,0, 0.1))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,0, 1))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,1, 0.75))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(1,0,1, 0.75))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)))
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Plot the data as a line with confidence intervals
plot(x=data$time, y=data$asd, type="l", bty="n", las=1, ylim=range(c(data$asd, data$upper, data$lower)), lwd=2, lty=3)
# Add confidence intervals
polygon(x=c(data$time, rev(data$time)), y=c(data$lower, rev(data$upper)), border=rgb(0,0,0,0), col=rgb(0,0,0, 0.25))
# Set the path variable
path <- "/home/josephcrispell/Desktop/Research/RepublicOfIreland/Mbovis/Monaghan/Fastqs_24-09-19/FASTQC/"
# Read in the FASTQC file summary table
summaryFile <- paste0(path, "Fastqc_summary_24-09-19.txt")
summary <- read.table(summaryFile, header=TRUE, sep="\t", stringsAsFactors=FALSE)
# Look at GC distribution
hist(summary$GC, breaks=20, las=1)
boxplot(summary$LeftTrim, summary$RightTrim, names=c("LEFT", "RIGHT"), las=1, frame=FALSE,
main="Trimming suggestions", outcol=rgb(0,0,0, 0.1), pch=19)
# Check adapter flag
table(summary$AdapterContentFlag)
head(summary])
head(summary)
# Look at the number of reads distribution
hist(summary$NumberReads, breaks=100, las=1)
summary(summary$NumberReads)
summary$FileName[which(summary$NumberReads < 250000)]
summary[which(summary$NumberReads < 250000), c("FileName", "NumberReads")]
# Sort the file names
summary <- summary[order(summary$FileName), ]
# Look at GC distribution
hist(summary$GC, breaks=20, las=1)
boxplot(summary$LeftTrim, summary$RightTrim, names=c("LEFT", "RIGHT"), las=1, frame=FALSE,
main="Trimming suggestions", outcol=rgb(0,0,0, 0.1), pch=19)
# Check adapter flag
table(summary$AdapterContentFlag)
# Look at the number of reads distribution
hist(summary$NumberReads, breaks=100, las=1)
summary[which(summary$NumberReads < 250000), c("FileName", "NumberReads")]
summary[which(summary$NumberReads > 1000000), c("FileName", "NumberReads")]
summary[which(summary$GC != 65), c("FileName", "NumberReads")]
summary[which(summary$GC != 65), c("FileName", "GC")]
# Look at the read length distribution
table(summary$ReadLength)
path <- "/home/josephcrispell/Desktop/Research/RepublicOfIreland/Mbovis/Monaghan/vcfFiles/"
##########################
# Read in coverage files #
##########################
# # Read in the genome coverage file
# genomeCoverageFile <- paste(path, "genomeCoverageSummary_DP-20_21-07-2017.txt", sep="")
# genomeCoverage <- read.table(genomeCoverageFile, header=TRUE, stringsAsFactors=FALSE)
# Read in the isolate coverage file
isolateCoverageFile <- paste(path, "isolateCoverageSummary_DP-20_30-07-2019.txt", sep="")
isolateCoverage <- read.table(isolateCoverageFile, header=TRUE, stringsAsFactors=FALSE)
# Read in the isolate coverage file
isolateCoverageFile <- paste(path, "isolateCoverageSummary_DP-20_24-09-2019.txt", sep="")
isolateCoverage <- read.table(isolateCoverageFile, header=TRUE, stringsAsFactors=FALSE)
# Parse the Isolate column
isolateCoverage$IsolateID <- parseIsolateColumn(isolateCoverage$IsolateID)
parseIsolateColumn <- function(column){
ids <- c()
for(i in 1:length(column)){
parts <- strsplit(column[i], split="_")[[1]]
ids[i] <- paste(parts[1], "_", parts[2], sep="")
}
return(ids)
}
# Parse the Isolate column
isolateCoverage$IsolateID <- parseIsolateColumn(isolateCoverage$IsolateID)
plot(y=isolateCoverage$PercentageCoverage,
x=isolateCoverage$MeanDepth,
las=1, ylab="Proportion", main="Proportion of M. bovis Genome with >19 mapped reads",
xlab="Mean Read Depth", pch=16, cex=3,
col=ifelse(grepl(x=isolateCoverage$IsolateID, pattern="WB"), rgb(1,0,0, 0.5),
rgb(0,0,1, 0.5)))
head(isolateCoverage)
isolateCoverage[isolateCoverage$PercentageCoverage < 0.1, ]
remove.packages("pathogenGenomicsWorkshop")
devtools::install_github("JosephCrispell/pathogeGenomicsWorkshop")
devtools::install_github("JosephCrispell/pathogenGenomicsWorkshop")
remove.packages("pathogenGenomicsWorkshop")
packageDirectory <- "/home/josephcrispell/Desktop/pathogenGenomicsWorkshop/"
setwd(packageDirectory)
document()
library("devtools")
library("roxygen2")
document()
# Load libraries
library(ape)
# Read in the ebola FASTA file
fastaFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola.fasta")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
rownames(nucleotideAlignment)
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="|")[[1]]
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
newNames
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\|")[[1]]
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
newNames
?gsub
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
parts[6] <- gsub(pattern="_", replacement="-")
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
parts[6] <- gsub(parts[6], pattern="_", replacement="-")
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
newNaems
newNames
?write.dna
# Read in the nucleotide alignment
fastaFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola.fasta")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
# COnvert the nucleotide characters to upper case
nucleotideAlignment <- toupper(nucleotideAlignment)
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
parts[6] <- gsub(parts[6], pattern="_", replacement="-")
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
rownames(nucleotideAlignment) <- newNames
outputFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola_parsed.fasta")
write.dna(nucleotideAlignment, outputFile, format="fasta")
write.dna(nucleotideAlignment, outputFile, format="fasta", colsep="")
# Count the nucleotides at each site in the alignment
nucleotideCountsAtEachSite <- countNucleotidesAtEachSite(nucleotideAlignment)
library(pathogenGenomicsWorkshop)
# Read in the nucleotide alignment
fastaFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola.fasta")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
# Convert the nucleotide characters to upper case
nucleotideAlignment <- toupper(nucleotideAlignment)
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
parts[6] <- gsub(parts[6], pattern="_", replacement="-")
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
rownames(nucleotideAlignment) <- newNames
# Count the nucleotides at each site in the alignment
nucleotideCountsAtEachSite <- countNucleotidesAtEachSite(nucleotideAlignment)
hist(nucleotideCountsAtEachSite)
?write.table
seq_len(ncol(nucleotideAlignment))
# Read in the nucleotide alignment
fastaFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola.fasta")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
# Convert the nucleotide characters to upper case
nucleotideAlignment <- toupper(nucleotideAlignment)
#### Remake the sequence names ####
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
parts[6] <- gsub(parts[6], pattern="_", replacement="-")
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
rownames(nucleotideAlignment) <- newNames
#### Check for uninformative sites ####
# Count the nucleotides at each site in the alignment
nucleotideCountsAtEachSite <- countNucleotidesAtEachSite(nucleotideAlignment)
# Identify the uninformative sites
uninformativeSites <- which(nucleotideCountsAtEachSite < 2)
# Create a new nucleotide alignment without the uninformative sites
nucleotideAlignmentInformative <- nucleotideAlignment[, -uninformativeSites]
# Create a dataframe to record the positions of the variant positions that were retained
positions <- seq_len(ncol(nucleotideAlignment))
informativePositions <- data.frame("Position"=positions[-uninformativeSites])
informativePositions
# Write the informative FASTA to file
outputFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola_parsed.fasta")
write.dna(nucleotideAlignmentInformative, outputFile, format="fasta", colsep="")
# Write the gneome positions to file
outputFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/Ebola_FASTApositions.txt")
write.table(informativePositions, file=outputFile, quote=FALSE, sep="\t", row.names=FALSE)
# Read in the nucleotide alignment
fastaFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola.fasta")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
# Convert the nucleotide characters to upper case
nucleotideAlignment <- toupper(nucleotideAlignment)
# Replace any gaps with Ns
nucleotideAlignment[nucleotideAlignment == "-"] <- "N"
newNames <- c()
for(i in seq_len(nrow(nucleotideAlignment))){
parts <- strsplit(rownames(nucleotideAlignment)[i], split="\\|")[[1]]
parts[6] <- gsub(parts[6], pattern="_", replacement="-")
newNames[i] <- paste0("Seq-", i, "_", parts[6], "_", parts[4])
}
rownames(nucleotideAlignment) <- newNames
#### Check for uninformative sites ####
# Count the nucleotides at each site in the alignment
nucleotideCountsAtEachSite <- countNucleotidesAtEachSite(nucleotideAlignment)
# Identify the uninformative sites
uninformativeSites <- which(nucleotideCountsAtEachSite < 2)
# Create a new nucleotide alignment without the uninformative sites
nucleotideAlignmentInformative <- nucleotideAlignment[, -uninformativeSites]
# Create a dataframe to record the positions of the variant positions that were retained
positions <- seq_len(ncol(nucleotideAlignment))
informativePositions <- data.frame("Position"=positions[-uninformativeSites])
#### Print the fasta to file ####
# Write the informative FASTA to file
outputFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/ebola_parsed.fasta")
write.dna(nucleotideAlignmentInformative, outputFile, format="fasta", colsep="")
# Write the gneome positions to file
outputFile <- paste0("~/Desktop/pathogenGenomicsWorkshop/inst/extdata/Ebola_FASTApositions.txt")
write.table(informativePositions, file=outputFile, quote=FALSE, sep="\t", row.names=FALSE)
knitr::opts_chunk$set(echo = TRUE)
# Read in the FASTA file
fastaFile <- system.file("extdata", "ebola_parsed.fasta", package = "pathogenGenomicsWorkshop")
nucleotideAlignment <- read.dna(fastaFile, format = "fasta", as.character=TRUE)
remove.packages("pathogenGenomicsWorkshop")
library("devtools")
library("roxygen2")
packageDirectory <- "/home/josephcrispell/Desktop/pathogenGenomicsWorkshop/"
twd(packageDirectory)
setwd(packageDirectory)
packageDirectory <- "~/Desktop/pathogenGenomicsWorkshop/"
setwd(packageDirectory)
document()
